{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363db8bc",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de7a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from torch import tensor\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio\n",
    "import concurrent.futures\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb59076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D,Conv2DTranspose, LeakyReLU, Dropout, concatenate, Multiply,ReLU\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7047f2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for Training\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Using GPU for Training\")\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "else:\n",
    "    print(\"Using CPU for Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51638bb4",
   "metadata": {},
   "source": [
    "## attnunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a69b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb95d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3ae0e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "# #definig the convolution block that consist of 2 conv layers.\n",
    "\n",
    "# def conv_block(input,no_filter,f_size,BN = False,drop_out = 0):\n",
    "#     x = tf.keras.layers.Conv2D(no_filter,f_size, padding = \"same\")(input)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "#     if BN:\n",
    "#         x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "#     residual = x\n",
    "#     x = tf.keras.layers.Conv2D(no_filter,f_size,padding = \"same\")(x)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "#     if BN :\n",
    "#         x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "#     if drop_out > 0 :\n",
    "#         x = tf.keras.layers.Dropout(drop_out)(x)\n",
    "#     x = tf.keras.layers.Add()([x, residual])\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def att_block(x, g, desired_dimensionality):\n",
    "#     x_shape = x.shape\n",
    "#     g_shape = g.shape\n",
    "    \n",
    "    \n",
    "#     # strides for xl should be 2 to equal the shapes before addition\n",
    "#     xl = tf.keras.layers.Conv2D(desired_dimensionality, (1, 1),strides=(2,2), padding=\"same\")(x)\n",
    "#     xl = LeakyReLU(alpha=0.2)(xl)\n",
    "    \n",
    "#     gl = tf.keras.layers.Conv2D(desired_dimensionality, (1, 1), padding=\"same\")(g)\n",
    "#     gl = LeakyReLU(alpha=0.2)(gl)\n",
    "    \n",
    "#     xg = tf.keras.layers.Add()([xl, gl])\n",
    "#     xg = LeakyReLU(alpha=0.2)(xg)\n",
    "#     xg = tf.keras.layers.Conv2D(1, (1, 1), activation=\"sigmoid\", padding=\"same\")(xg)\n",
    "#     xg_shape = xg.shape\n",
    "#     # Transpose xg to match the shape of x\n",
    "#     xg = tf.keras.layers.Conv2DTranspose(1, (x_shape[1], x_shape[2]), strides=(x_shape[1] // xg_shape[1], x_shape[2] // xg_shape[2]), padding='same')(xg)\n",
    "    \n",
    "#     output = tf.keras.layers.Multiply()([xg, x])\n",
    "#     return output\n",
    "\n",
    "\n",
    "# def att_model(no_filter, input_shape=(224, 224, 3)):\n",
    "#     # down-sampling process\n",
    "#     inputs = tf.keras.layers.Input(input_shape, dtype=tf.float32)\n",
    "#     x1 = conv_block(inputs, no_filter, (5,5), BN=True, drop_out=0.5)\n",
    "#     pool1 = tf.keras.layers.MaxPooling2D(2, 2)(x1)\n",
    "\n",
    "#     x2 = conv_block(pool1, 2 * no_filter, (5,5), BN=True, drop_out=0.5)\n",
    "#     pool2 = tf.keras.layers.MaxPooling2D(2, 2)(x2)\n",
    "\n",
    "#     x3 = conv_block(pool2, 4 * no_filter, (5,5), BN=True, drop_out=0.5)\n",
    "#     pool3 = tf.keras.layers.MaxPooling2D(2, 2)(x3)\n",
    "\n",
    "#     x4 = conv_block(pool3, 8 * no_filter, (5,5), BN=True, drop_out=0.5)\n",
    "#     pool4 = tf.keras.layers.MaxPooling2D(2, 2)(x4)\n",
    "\n",
    "#     # bottle-neck\n",
    "#     x5 = conv_block(pool4, 16 * no_filter, (5,5), BN=True, drop_out=0.5)\n",
    "\n",
    "#     # up-sampling layers\n",
    "\n",
    "#     x6 = att_block(x4, x5, no_filter * 2)\n",
    "#     u6 = tf.keras.layers.Conv2DTranspose(8 * no_filter,(5,5),strides=(2,2) ,padding='same')(x5)\n",
    "#     concate1 = tf.keras.layers.Concatenate()([x6, u6])\n",
    "#     conv6 = conv_block(concate1, 8 * no_filter, (5,5), BN=True, drop_out=0.5)\n",
    "    \n",
    "#     x7= att_block(x3,conv6, no_filter*2)\n",
    "#     u7= tf.keras.layers.Conv2DTranspose(4 * no_filter,(5,5),strides=(2,2), padding='same')(conv6) \n",
    "#     concate2 = tf.keras.layers.Concatenate()([x7,u7])\n",
    "#     conv7 = conv_block(concate2,4*no_filter,(5,5),BN = True,drop_out = 0.5) \n",
    "\n",
    "\n",
    "#     x8= att_block(x2,conv7, no_filter*2)\n",
    "#     u8= tf.keras.layers.Conv2DTranspose(2 * no_filter,(5,5),strides=(2,2), padding='same')(conv7) \n",
    "#     concate3 = tf.keras.layers.Concatenate()([x8,u8])\n",
    "#     conv8 = conv_block(concate3,2*no_filter,(5,5),BN = True,drop_out = 0.5) \n",
    "\n",
    "\n",
    "\n",
    "#     x9= att_block(x1,conv8, no_filter*2)\n",
    "#     u9= tf.keras.layers.Conv2DTranspose(no_filter,(5,5),strides=(2,2),padding='same')(conv8) \n",
    "#     concate4 = tf.keras.layers.Concatenate()([x9,u9])\n",
    "#     conv9 = conv_block(concate4,no_filter,(5,5),BN = True,drop_out = 0.5) \n",
    "    \n",
    "\n",
    "\n",
    "#     conv_final = tf.keras.layers.Conv2D(1, kernel_size=(4,4),dilation_rate=(2, 2), strides=(1,1),activation='sigmoid', padding='same')(conv8)\n",
    "#     conv_final =tf.keras.layers.BatchNormalization(axis=3)(conv_final)\n",
    "#     conv_final = tf.keras.layers.Conv2DTranspose(1,(5,5),strides=(2,2), activation=\"sigmoid\", padding='same')(conv_final)\n",
    "    \n",
    "#     output = Multiply()([conv_final, inputs])\n",
    "\n",
    "#     return tf.keras.Model(inputs, output)\n",
    "\n",
    "\n",
    "\n",
    "# model = att_model(16,input_shape=(128,64,1) )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0c3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f182bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9999c12",
   "metadata": {},
   "source": [
    "# Real Value Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff29d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, concatenate, Multiply, Activation\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Activation, Add, Multiply\n",
    "\n",
    "# def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n",
    "#     # theta_x(?,g_height,g_width,inter_channel)\n",
    "#     theta_x = Conv2D(inter_channel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "#     # phi_g(?,g_height,g_width,inter_channel)\n",
    "#     phi_g = Conv2D(inter_channel, (1, 1), strides=(1, 1), padding='same')(g)\n",
    "\n",
    "#     # f(?,g_height,g_width,inter_channel)\n",
    "#     f = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "\n",
    "#     # psi_f(?,g_height,g_width,1)\n",
    "#     psi_f = Conv2D(1, (1, 1), strides=(1, 1), padding='same')(f)\n",
    "#     rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "#     # rate(?,x_height,x_width)\n",
    "#     # att_x(?,x_height,x_width,x_channel)\n",
    "#     att_x = Multiply()([x, rate])\n",
    "\n",
    "#     return att_x\n",
    "\n",
    "# def unet_with_attention(input_shape):\n",
    "#     # Encoder\n",
    "#     inputs = Input(input_shape)\n",
    "#     conv1 = Conv2D(16, (5, 5), strides=(2, 2), padding='same')(inputs)\n",
    "#     conv1 = LeakyReLU(alpha=0.2)(conv1)\n",
    "#     conv1 = Dropout(0.5)(conv1)\n",
    "\n",
    "#     conv2 = Conv2D(32, (5, 5), strides=(2, 2), padding='same')(conv1)\n",
    "#     conv2 = LeakyReLU(alpha=0.2)(conv2)\n",
    "#     conv2 = Dropout(0.5)(conv2)\n",
    "\n",
    "#     conv3 = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(conv2)\n",
    "#     conv3 = LeakyReLU(alpha=0.2)(conv3)\n",
    "#     conv3 = Dropout(0.5)(conv3)\n",
    "\n",
    "#     conv4 = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(conv3)\n",
    "#     conv4 = LeakyReLU(alpha=0.2)(conv4)\n",
    "#     conv4 = Dropout(0.5)(conv4)\n",
    "\n",
    "#     conv5 = Conv2D(256, (5, 5), strides=(2, 2), padding='same')(conv4)\n",
    "#     conv5 = LeakyReLU(alpha=0.2)(conv5)\n",
    "#     conv5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "#     #bottleneck\n",
    "#     conv6 = Conv2D(512, (5, 5), strides=(2, 2), padding='same')(conv5)\n",
    "#     conv6 = LeakyReLU(alpha=0.2)(conv6)\n",
    "#     conv6 = Dropout(0.5)(conv6)\n",
    "\n",
    "#     # Decoder with Attention\n",
    "#     up1 = Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same')(conv6)\n",
    "#     up1 = LeakyReLU(alpha=0.2)(up1)\n",
    "#     attention1 = attention_block_2d(up1, conv5, 128)\n",
    "#     merge1 = concatenate([conv5, attention1], axis=3)\n",
    "#     merge1 = Dropout(0.5)(merge1)\n",
    "\n",
    "#     up2 = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(merge1)\n",
    "#     up2 = LeakyReLU(alpha=0.2)(up2)\n",
    "#     attention2 = attention_block_2d(up2, conv4, 64)\n",
    "#     merge2 = concatenate([conv4, attention2], axis=3)\n",
    "#     merge2 = Dropout(0.5)(merge2)\n",
    "\n",
    "#     up3 = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(merge2)\n",
    "#     up3 = LeakyReLU(alpha=0.2)(up3)\n",
    "#     attention3 = attention_block_2d(up3, conv3, 32)\n",
    "#     merge3 = concatenate([conv3, attention3], axis=3)\n",
    "#     merge3 = Dropout(0.5)(merge3)\n",
    "\n",
    "#     up4 = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same')(merge3)\n",
    "#     up4 = LeakyReLU(alpha=0.2)(up4)\n",
    "#     attention4 = attention_block_2d(up4, conv2, 16)\n",
    "#     merge4 = concatenate([conv2, attention4], axis=3)\n",
    "#     merge4 = Dropout(0.5)(merge4)\n",
    "\n",
    "#     up5 = Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same')(merge4)\n",
    "#     up5 = LeakyReLU(alpha=0.2)(up5)\n",
    "#     attention5 = attention_block_2d(up5, conv1, 8)\n",
    "#     merge5 = concatenate([conv1, attention5], axis=3)\n",
    "#     merge5 = Dropout(0.5)(merge5)\n",
    "\n",
    "#     # Add the final convolution layer\n",
    "#     conv = Conv2D(1, (4, 4), dilation_rate=(2, 2), activation='sigmoid', padding='same')(merge5)\n",
    "\n",
    "#     output = Conv2DTranspose(1, (5, 5), strides=(2, 2), activation=\"sigmoid\", padding='same')(conv)\n",
    "#     output = Multiply()([output, inputs])\n",
    "\n",
    "#     model = Model(inputs=inputs, outputs=output)\n",
    "#     return model\n",
    "\n",
    "# # Define the input shape (adjust as needed)\n",
    "# input_shape = (128, 64, 1)  # Adjusted to (128, 128, 1)\n",
    "\n",
    "# # Create the U-Net model with attention\n",
    "# model_with_attention = unet_with_attention(input_shape)\n",
    "\n",
    "# # Print the model summary\n",
    "# model_with_attention.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614c6d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 64, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 32, 16)   416         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 32, 16)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64, 32, 16)   0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 16, 32)   12832       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 16, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 16, 32)   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 8, 64)    51264       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 8, 64)    0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 8, 64)    0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 4, 128)    204928      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 4, 128)    0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 8, 4, 128)    0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 2, 256)    819456      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 4, 2, 256)    0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 2, 256)    0           ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 2, 1, 512)    3277312     ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 2, 1, 512)    0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 2, 1, 512)    0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 4, 2, 256)   3277056     ['dropout_5[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 4, 2, 256)    0           ['conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 2, 512)    0           ['dropout_4[0][0]',              \n",
      "                                                                  'leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 2, 512)    0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 8, 4, 128)   1638528     ['dropout_6[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 8, 4, 128)    0           ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 4, 256)    0           ['dropout_3[0][0]',              \n",
      "                                                                  'leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 8, 4, 256)    0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 16, 8, 64)   409664      ['dropout_7[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 16, 8, 64)    0           ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 16, 8, 128)   0           ['dropout_2[0][0]',              \n",
      "                                                                  'leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 16, 8, 128)   0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 32, 16, 32)  102432      ['dropout_8[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 32, 16, 32)   0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 16, 64)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 32, 16, 64)   0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 64, 32, 16)  25616       ['dropout_9[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 64, 32, 16)   0           ['conv2d_transpose_4[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 32, 32)   0           ['dropout[0][0]',                \n",
      "                                                                  'leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 64, 32, 32)   0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 32, 1)    513         ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 128, 64, 1)  26          ['conv2d_6[0][0]']               \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 128, 64, 1)   0           ['conv2d_transpose_5[0][0]',     \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,820,043\n",
      "Trainable params: 9,820,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def unet(input_shape):\n",
    "    # Encoder\n",
    "    inputs = Input(input_shape)\n",
    "    conv1 = Conv2D(16, (3,3), strides=(2, 2), padding='same')(inputs)\n",
    "    conv1 = LeakyReLU(alpha=0.2)(conv1)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "\n",
    "    conv2 = Conv2D(32, (3,3), strides=(2, 2), padding='same')(conv1)\n",
    "    conv2 = LeakyReLU(alpha=0.2)(conv2)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, (3,3), strides=(2, 2), padding='same')(conv2)\n",
    "    conv3 = LeakyReLU(alpha=0.2)(conv3)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "\n",
    "    conv4 = Conv2D(128, (3,3), strides=(2, 2), padding='same')(conv3)\n",
    "    conv4 = LeakyReLU(alpha=0.2)(conv4)\n",
    "    conv4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    conv5 = Conv2D(256, (3,3), strides=(2, 2), padding='same')(conv4)\n",
    "    conv5 = LeakyReLU(alpha=0.2)(conv5)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    conv6 = Conv2D(512, (3,3), strides=(2, 2), padding='same')(conv5)\n",
    "    conv6 = LeakyReLU(alpha=0.2)(conv6)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "\n",
    "    # Decoder\n",
    "    up1 = Conv2DTranspose(256, (3,3), strides=(2, 2), padding='same')(conv6)\n",
    "    up1 = LeakyReLU(alpha=0.2)(up1)\n",
    "    merge1 = concatenate([conv5, up1], axis=3)  # Changed axis to concatenate along the channel dimension\n",
    "    merge1 = Dropout(0.5)(merge1)\n",
    "\n",
    "    up2 = Conv2DTranspose(128, (3,3), strides=(2, 2), padding='same')(merge1)\n",
    "    up2 = LeakyReLU(alpha=0.2)(up2)\n",
    "    merge2 = concatenate([conv4, up2], axis=3)  # Changed axis to concatenate along the channel dimension\n",
    "    merge2 = Dropout(0.5)(merge2)\n",
    "\n",
    "    up3 = Conv2DTranspose(64, (3,3), strides=(2, 2), padding='same')(merge2)\n",
    "    up3 = LeakyReLU(alpha=0.2)(up3)\n",
    "    merge3 = concatenate([conv3, up3], axis=3)  # Changed axis to concatenate along the channel dimension\n",
    "    merge3 = Dropout(0.5)(merge3)\n",
    "\n",
    "    up4 = Conv2DTranspose(32, (3,3), strides=(2, 2), padding='same')(merge3)\n",
    "    up4 = LeakyReLU(alpha=0.2)(up4)\n",
    "    merge4 = concatenate([conv2, up4], axis=3)  # Changed axis to concatenate along the channel dimension\n",
    "    merge4 = Dropout(0.5)(merge4)\n",
    "\n",
    "    up5 = Conv2DTranspose(16, (3,3), strides=(2, 2), padding='same')(merge4)\n",
    "    up5 = LeakyReLU(alpha=0.2)(up5)\n",
    "    merge5 = concatenate([conv1, up5], axis=3)  # Changed axis to concatenate along the channel dimension\n",
    "    merge5 = Dropout(0.5)(merge5)\n",
    "\n",
    "    # Add the final convolution layer\n",
    "    conv = Conv2D(1, (4, 4), dilation_rate=(2, 2), activation='sigmoid', padding='same')(merge5)\n",
    "\n",
    "    output = Conv2DTranspose(1, (3,3), strides=(2, 2), activation=\"sigmoid\", padding='same')(conv)\n",
    "    output = Multiply()([output, inputs])\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Define the input shape (adjust as needed)\n",
    "input_shape = (128, 64, 1)  # Adjusted to (128, 128, 1)\n",
    "\n",
    "# Create the U-Net model\n",
    "model = unet(input_shape)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4b645",
   "metadata": {},
   "source": [
    "## Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da0079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading clean_stft_wgn5db: 4213it [00:02, 1874.03it/s]\n",
      "Loading clean_stft_wgn-5db: 4213it [00:02, 1752.94it/s]\n",
      "Loading clean_stft_wgn0db: 4213it [00:02, 1895.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from a single .mat file\n",
    "def load_data(file_path):\n",
    "    loaded_mat = scipy.io.loadmat(file_path)\n",
    "    return loaded_mat['Segment_clean']  # Replace with the actual variable name\n",
    "\n",
    "# Define the root folder containing subfolders with .mat files\n",
    "root_folder = 'data/dataformodel_noaug/'\n",
    "\n",
    "# Specify subfolders of interest\n",
    "subfolders = [\n",
    "#     'clean_stft_pink-5db',\n",
    "#     'clean_stft_pink0db',\n",
    "#     'clean_stft_pink5db',\n",
    "    'clean_stft_wgn5db',\n",
    "    'clean_stft_wgn-5db',\n",
    "    'clean_stft_wgn0db',\n",
    "#     'clean_stft_han',\n",
    "#    'clean_stft_red-5db_Hristo',\n",
    "#     'clean_stft_red0db_Hristo',\n",
    "#     'clean_stft_red5db_Hristo',\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store loaded data\n",
    "loaded_data = []\n",
    "\n",
    "# Loop through each subfolder and load data\n",
    "for subfolder in subfolders:\n",
    "    mat_folder = os.path.join(root_folder, subfolder)\n",
    "\n",
    "    # List all .mat files in the current subfolder\n",
    "    mat_files = [os.path.join(mat_folder, filename) for filename in os.listdir(mat_folder) if filename.endswith('.mat')]\n",
    "\n",
    "    # Use concurrent processing to load data from multiple files simultaneously\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        current_loaded_data = list(tqdm.tqdm(executor.map(load_data, mat_files), desc=f'Loading {subfolder}'))\n",
    "\n",
    "    # Extend the loaded_data list with data from the current subfolder\n",
    "    loaded_data.extend(current_loaded_data)\n",
    "\n",
    "# Stack all loaded data into a single array\n",
    "clean_data = np.stack(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e3bd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12639, 128, 64), 0.8289681539628652, 0.0003554751293048475)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.shape,np.std(np.real(clean_data)),np.mean(np.real(clean_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f73a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d33221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4213it [00:02, 1752.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from a single .mat file\n",
    "def load_data(file_path):\n",
    "    loaded_mat = scipy.io.loadmat(file_path)\n",
    "    return loaded_mat['Segment_clean']  # Replace with the actual variable name\n",
    "\n",
    "# Define the folder containing the .mat files\n",
    "mat_folder = 'data/dataformodel_noaug/clean_stft_wgn-5db'  # Replace with the actual path\n",
    "\n",
    "# Initialize an empty list to store loaded data\n",
    "loaded_data = []\n",
    "\n",
    "# List all .mat files in the folder\n",
    "mat_files = [os.path.join(mat_folder, filename) for filename in os.listdir(mat_folder) if filename.endswith('.mat')]\n",
    "\n",
    "# Use concurrent processing to load data from multiple files simultaneously\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    loaded_data = list(tqdm.tqdm(executor.map(load_data, mat_files)))\n",
    "\n",
    "# Concatenate all loaded data into a single variable\n",
    "clean_data = np.stack(loaded_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6003018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.01583342e-02+0.00000000e+00j,\n",
       "          1.48124459e-04+0.00000000e+00j,\n",
       "         -1.31348991e-01+0.00000000e+00j, ...,\n",
       "         -9.67382393e-04+0.00000000e+00j,\n",
       "          6.20926666e-02+0.00000000e+00j,\n",
       "          1.19025707e-01+0.00000000e+00j],\n",
       "        [ 1.08736900e-02-6.97484940e-03j,\n",
       "         -4.14627525e-02+2.75162301e-02j,\n",
       "          2.29003247e-02+1.82192345e-01j, ...,\n",
       "          9.60196572e-03+1.82953608e-02j,\n",
       "         -4.74627357e-02-4.42160033e-02j,\n",
       "          1.56069789e-03-1.18564067e-01j],\n",
       "        [-7.23952182e-03+3.09935212e-02j,\n",
       "          1.14322196e-01+1.62646181e-02j,\n",
       "          1.41347812e-01-2.25926274e-01j, ...,\n",
       "          5.05237976e-02+2.00661526e-03j,\n",
       "          2.91857956e-03+6.23733478e-02j,\n",
       "         -1.15884004e-01-1.02860766e-02j],\n",
       "        ...,\n",
       "        [ 6.40714388e-05-4.23346490e-04j,\n",
       "         -4.11609985e-04+1.16640631e-03j,\n",
       "          9.57692710e-04-2.21065042e-03j, ...,\n",
       "         -1.44351935e-04+1.58730087e-04j,\n",
       "          1.49992891e-04-1.75334763e-04j,\n",
       "         -3.20937491e-05+4.85090375e-05j],\n",
       "        [-7.67740193e-04+2.60347300e-04j,\n",
       "          3.30215559e-04-1.77281335e-04j,\n",
       "         -1.97202889e-03-5.77740324e-04j, ...,\n",
       "          5.47376351e-05+1.08535240e-04j,\n",
       "         -1.49091476e-04-1.07410089e-04j,\n",
       "         -8.80531950e-05+4.82533472e-05j],\n",
       "        [ 2.50122940e-04+9.62021096e-04j,\n",
       "         -2.82981660e-04+5.76043633e-04j,\n",
       "         -2.33173994e-04+1.77312695e-03j, ...,\n",
       "          6.33711321e-05+9.40174324e-05j,\n",
       "         -5.46456324e-05+1.46800019e-04j,\n",
       "          3.56331872e-05+1.72038479e-04j]],\n",
       "\n",
       "       [[ 9.04370013e-02+0.00000000e+00j,\n",
       "          4.04732490e-02+0.00000000e+00j,\n",
       "          7.32917921e-02+0.00000000e+00j, ...,\n",
       "         -7.83634424e-01+0.00000000e+00j,\n",
       "         -4.73299681e+00+0.00000000e+00j,\n",
       "         -3.36922466e+00+0.00000000e+00j],\n",
       "        [ 1.71890211e-02-7.13196282e-02j,\n",
       "          6.50181702e-03-4.08132928e-02j,\n",
       "         -4.23800732e-02-5.20547739e-02j, ...,\n",
       "          1.47022123e+00+1.38222381e-01j,\n",
       "          1.20050489e+00+4.86303084e+00j,\n",
       "         -2.01979051e+00+2.80908763e+00j],\n",
       "        [-1.54165359e-02-1.66363318e-02j,\n",
       "         -3.68451920e-02-3.11845361e-02j,\n",
       "          5.94416418e-04+6.70525859e-02j, ...,\n",
       "         -1.55504620e+00-2.46842588e+00j,\n",
       "          4.90398349e+00-1.37773830e+00j,\n",
       "          1.80169861e+00+2.94570590e+00j],\n",
       "        ...,\n",
       "        [-1.25670669e-04-2.21913226e-05j,\n",
       "          1.28801540e-04-4.35500261e-05j,\n",
       "         -3.08072310e-04-3.38010681e-04j, ...,\n",
       "         -4.02609513e-03-5.84952055e-03j,\n",
       "          3.15762735e-04+6.84256345e-03j,\n",
       "         -1.41202094e-04-4.46042170e-03j],\n",
       "        [-4.15876675e-05+5.53232299e-05j,\n",
       "         -5.70298402e-05-7.95044848e-05j,\n",
       "         -1.16578689e-04+4.47457168e-04j, ...,\n",
       "         -5.46923042e-03+4.27975912e-03j,\n",
       "          4.20844213e-03+3.55017197e-04j,\n",
       "         -2.58140324e-03-1.35172291e-03j],\n",
       "        [ 1.69806994e-05+7.95265733e-05j,\n",
       "         -3.53355848e-05+9.96103167e-05j,\n",
       "          3.15454338e-04-1.36804904e-04j, ...,\n",
       "          2.73883058e-03+4.94432174e-03j,\n",
       "          5.11916182e-04-1.23840958e-03j,\n",
       "         -1.36046273e-03+1.43351594e-03j]],\n",
       "\n",
       "       [[ 1.21082565e+00+0.00000000e+00j,\n",
       "          3.28256979e+00+0.00000000e+00j,\n",
       "          1.19646144e+00+0.00000000e+00j, ...,\n",
       "         -1.10531933e-02+0.00000000e+00j,\n",
       "         -7.40730633e-03+0.00000000e+00j,\n",
       "          5.52382913e-04+0.00000000e+00j],\n",
       "        [-1.68371916e+00-1.04687604e+00j,\n",
       "          9.62211538e-02-3.56385395e+00j,\n",
       "          1.62192382e+00-7.77940338e-01j, ...,\n",
       "         -3.31947507e-03+8.87774741e-03j,\n",
       "          2.82838734e-05+6.49492447e-03j,\n",
       "         -5.19483047e-03-3.52510212e-04j],\n",
       "        [-5.64250887e-01+1.46529812e+00j,\n",
       "         -4.15835249e+00+4.48294561e-01j,\n",
       "          6.43894504e-01-2.60467656e+00j, ...,\n",
       "          4.16319972e-03+4.83013948e-03j,\n",
       "          3.76538408e-03-1.90473506e-03j,\n",
       "          5.79255559e-04+9.96710653e-03j],\n",
       "        ...,\n",
       "        [ 4.47389299e-03-1.09544124e-04j,\n",
       "         -9.09126692e-03+7.60882336e-04j,\n",
       "          6.03996733e-03-1.70698209e-03j, ...,\n",
       "         -9.51436373e-05-7.64591922e-05j,\n",
       "          2.49308371e-04+1.81563535e-04j,\n",
       "         -8.55030281e-05-2.15937812e-04j],\n",
       "        [-2.40491072e-03-1.48245563e-03j,\n",
       "          8.59842101e-04+5.85898672e-03j,\n",
       "          1.24798959e-03-1.94720228e-03j, ...,\n",
       "         -7.63777634e-06+9.77192807e-05j,\n",
       "          5.42503806e-05-1.97711956e-04j,\n",
       "         -2.76071890e-04-2.43429879e-05j],\n",
       "        [ 6.06543486e-05+3.44053916e-03j,\n",
       "          2.72884823e-03-7.40456230e-04j,\n",
       "          2.35990183e-04-3.82713349e-03j, ...,\n",
       "          5.30290755e-05-1.67108639e-05j,\n",
       "         -1.12871207e-04+4.79300510e-05j,\n",
       "         -4.72143761e-05+3.04693051e-04j]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.25881061e+00+0.00000000e+00j,\n",
       "          4.93761856e+00+0.00000000e+00j,\n",
       "          5.28094595e+00+0.00000000e+00j, ...,\n",
       "          3.15224347e+00+0.00000000e+00j,\n",
       "          3.03372790e+00+0.00000000e+00j,\n",
       "          3.25439463e+00+0.00000000e+00j],\n",
       "        [ 8.66492534e-01-1.74029958e+00j,\n",
       "         -1.71045548e+00-4.72540862e+00j,\n",
       "          1.12880858e+00-4.18439927e+00j, ...,\n",
       "          1.17146426e-01-2.79616494e+00j,\n",
       "         -2.54074193e-01-2.62107526e+00j,\n",
       "          1.73348268e-01-2.71711592e+00j],\n",
       "        [-1.41522666e+00-2.39623385e+00j,\n",
       "         -3.25433333e+00+5.42859831e+00j,\n",
       "         -1.11490237e+00-5.01971636e+00j, ...,\n",
       "         -1.72424200e+00-8.55050960e-01j,\n",
       "         -1.78719760e+00+5.87523211e-01j,\n",
       "         -1.44066429e+00-3.01535734e-01j],\n",
       "        ...,\n",
       "        [-8.23909668e-04-1.37719868e-04j,\n",
       "         -4.08443230e-03+6.09587329e-03j,\n",
       "          1.07962572e-02-1.93509614e-03j, ...,\n",
       "          2.16367275e-03+4.02802657e-04j,\n",
       "         -3.53837589e-04-2.34288023e-04j,\n",
       "          2.03499346e-05+6.74371536e-05j],\n",
       "        [ 1.41317764e-03+1.93571737e-03j,\n",
       "          7.86677704e-03+1.39322977e-03j,\n",
       "         -7.83080735e-04-9.20210807e-03j, ...,\n",
       "          1.16181506e-03-1.60060982e-03j,\n",
       "         -2.71574274e-04+5.29925595e-07j,\n",
       "          1.02048830e-04-2.53417795e-05j],\n",
       "        [ 1.77212714e-03-3.70955707e-03j,\n",
       "          7.03694782e-05-8.17315735e-03j,\n",
       "         -5.37977076e-03+8.15024825e-06j, ...,\n",
       "         -8.21026739e-04-1.60039841e-03j,\n",
       "         -1.53169749e-04-9.73029668e-06j,\n",
       "         -4.27237163e-06-8.49407218e-05j]],\n",
       "\n",
       "       [[ 3.14260878e+00+0.00000000e+00j,\n",
       "          3.27123835e+00+0.00000000e+00j,\n",
       "          3.26074818e+00+0.00000000e+00j, ...,\n",
       "          3.25500069e+00+0.00000000e+00j,\n",
       "          3.25235321e+00+0.00000000e+00j,\n",
       "          3.25200856e+00+0.00000000e+00j],\n",
       "        [-1.08841715e-01-2.67660880e+00j,\n",
       "          1.80114060e-02-2.78595076e+00j,\n",
       "         -6.59912767e-03-2.76041840e+00j, ...,\n",
       "          2.22419937e-04-2.76348351e+00j,\n",
       "          1.78466765e-03-2.76048183e+00j,\n",
       "         -1.01932928e-03-2.75983687e+00j],\n",
       "        [-1.60888514e+00+1.69669522e-01j,\n",
       "         -1.66809892e+00-3.88042093e-02j,\n",
       "         -1.60070251e+00+2.90015071e-02j, ...,\n",
       "         -1.62939877e+00-8.80654193e-04j,\n",
       "         -1.62578194e+00-1.80464863e-03j,\n",
       "         -1.62397640e+00+1.58914503e-03j],\n",
       "        ...,\n",
       "        [ 4.28079404e-05-9.35736145e-05j,\n",
       "          9.63294907e-05+1.25102185e-04j,\n",
       "         -8.02760938e-05-1.74800843e-04j, ...,\n",
       "         -1.05552743e-04-8.40570437e-05j,\n",
       "          3.21067487e-05+5.22874248e-05j,\n",
       "         -1.44670566e-04-1.21456067e-06j],\n",
       "        [-2.83374527e-05-3.01558697e-05j,\n",
       "          2.12923942e-05-8.75444470e-05j,\n",
       "         -1.63303981e-04+4.13037553e-05j, ...,\n",
       "         -8.20187747e-05+7.98577550e-05j,\n",
       "          4.18475141e-05+1.72632347e-05j,\n",
       "          7.79651177e-05+1.06645135e-04j],\n",
       "        [-1.48742028e-05-1.77383134e-05j,\n",
       "         -5.29111817e-05+5.40008433e-05j,\n",
       "          1.88437388e-05+1.38839759e-04j, ...,\n",
       "          4.10678845e-05+7.09450247e-05j,\n",
       "          2.96379155e-05-3.63932020e-05j,\n",
       "          5.36223687e-05-1.37282599e-04j]],\n",
       "\n",
       "       [[ 3.25624841e+00+0.00000000e+00j,\n",
       "          3.25800398e+00+0.00000000e+00j,\n",
       "          3.24940125e+00+0.00000000e+00j, ...,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j],\n",
       "        [-1.99178417e-03-2.76433269e+00j,\n",
       "          8.97895765e-04-2.76592199e+00j,\n",
       "          5.57973439e-03-2.75877199e+00j, ...,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j],\n",
       "        [-1.62928763e+00+2.53083318e-03j,\n",
       "         -1.63030125e+00-5.90127557e-04j,\n",
       "         -1.62655754e+00-7.82597070e-03j, ...,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j],\n",
       "        ...,\n",
       "        [ 2.17889523e-04+1.56862297e-04j,\n",
       "          1.10819789e-05-1.98042790e-04j,\n",
       "         -3.50903062e-05+1.13998196e-05j, ...,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j],\n",
       "        [ 1.28410916e-04-1.96120456e-04j,\n",
       "         -2.11746108e-04-5.79500743e-05j,\n",
       "         -7.40517141e-05+5.85657578e-05j, ...,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j],\n",
       "        [-1.16662636e-04-8.68299951e-05j,\n",
       "         -5.28399988e-05+1.96826015e-04j,\n",
       "          4.68864936e-05+1.55525818e-04j, ...,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j,\n",
       "          0.00000000e+00+0.00000000e+00j]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10248a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data.shape,np.std(np.real(clean_data)),np.mean(np.real(clean_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00db8894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12639, 128, 64), (12639, 128, 64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_real = np.real(clean_data)\n",
    "clean_img  = np.imag(clean_data)\n",
    "clean_real.shape,clean_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79980cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# original_shape_clean = clean_real.shape\n",
    "# clean_data_2d = clean_real.reshape(-1, original_shape_clean[-1])\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler_clean = StandardScaler()\n",
    "\n",
    "# # Fit the scaler on your data and transform it\n",
    "# scaled_cleandata_2d = scaler_clean.fit_transform(clean_data_2d)\n",
    "\n",
    "# # Reshape the scaled data back to its original shape\n",
    "# scaled_clean_data = scaled_cleandata_2d.reshape(original_shape_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6eb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(scaled_clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d263f",
   "metadata": {},
   "source": [
    "## Noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c950d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading noisy_stft_wgn5db: 4213it [00:02, 1827.89it/s]\n",
      "Loading noisy_stft_wgn-5db: 4213it [00:02, 1678.53it/s]\n",
      "Loading noisy_stft_wgn0db: 4213it [00:02, 1654.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from a single .mat file\n",
    "def load_data(file_path):\n",
    "    loaded_mat = scipy.io.loadmat(file_path)\n",
    "    return loaded_mat['Segment_noisy']  # Replace with the actual variable name\n",
    "\n",
    "# Define the root folder containing subfolders with .mat files\n",
    "root_folder = 'data/dataformodel_noaug/'\n",
    "\n",
    "# Specify subfolders of interest\n",
    "subfolders = [\n",
    "#     'noisy_stft_pink-5db',\n",
    "#     'noisy_stft_pink0db',\n",
    "#     'noisy_stft_pink5db',\n",
    "    'noisy_stft_wgn5db',\n",
    "    'noisy_stft_wgn-5db',\n",
    "    'noisy_stft_wgn0db',\n",
    "#     'noisy_stft_han',\n",
    "#     'noisy_stft_red-5db_Hristo',\n",
    "#     'noisy_stft_red0db_Hristo',\n",
    "#     'noisy_stft_red5db_Hristo',\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store loaded data\n",
    "loaded_data = []\n",
    "\n",
    "# Loop through each subfolder and load data\n",
    "for subfolder in subfolders:\n",
    "    mat_folder = os.path.join(root_folder, subfolder)\n",
    "\n",
    "    # List all .mat files in the current subfolder\n",
    "    mat_files = [os.path.join(mat_folder, filename) for filename in os.listdir(mat_folder) if filename.endswith('.mat')]\n",
    "\n",
    "    # Use concurrent processing to load data from multiple files simultaneously\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        current_loaded_data = list(tqdm.tqdm(executor.map(load_data, mat_files), desc=f'Loading {subfolder}'))\n",
    "\n",
    "    # Extend the loaded_data list with data from the current subfolder\n",
    "    loaded_data.extend(current_loaded_data)\n",
    "\n",
    "# Stack all loaded data into a single array\n",
    "noisy_data = np.stack(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5dbe620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12639, 128, 64), 0.9561850481069908, 7.963804402420294e-05)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_data.shape,np.std(np.real(noisy_data)),np.mean(np.real(noisy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "166d6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4213it [00:02, 1788.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from a single .mat file\n",
    "def load_data(file_path):\n",
    "    loaded_mat = scipy.io.loadmat(file_path)\n",
    "    return loaded_mat['Segment_noisy']  # Replace with the actual variable name\n",
    "\n",
    "# Define the folder containing the .mat file\n",
    "mat_folder = 'data/dataformodel_noaug/noisy_stft_wgn-5db'  # Replace with the actual path\n",
    "\n",
    "# Initialize an empty list to store loaded data\n",
    "loaded_data = []\n",
    "\n",
    "# List all .mat files in the folder\n",
    "mat_files = [os.path.join(mat_folder, filename) for filename in os.listdir(mat_folder) if filename.endswith('.mat')]\n",
    "\n",
    "# Use concurrent processing to load data from multiple files simultaneously\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    loaded_data = list(tqdm.tqdm(executor.map(load_data, mat_files)))\n",
    "\n",
    "# Concatenate all loaded data into a single variable\n",
    "noisy_data = np.stack(loaded_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d53b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.08636244e+00+0.j        ,  3.56211699e-01+0.j        ,\n",
       "         -1.11889181e+00+0.j        , ...,  2.73568273e-01+0.j        ,\n",
       "         -1.17926995e-01+0.j        , -1.39323283e+00+0.j        ],\n",
       "        [ 7.78737269e-01-2.69618859j,  1.20977585e+00-0.1588504j ,\n",
       "         -2.10388009e-01+1.06510527j, ..., -2.85339903e-01-0.33983802j,\n",
       "          5.76239217e-01+0.03189136j,  1.86197689e-01+1.40566032j],\n",
       "        [-1.79043790e+00-0.59086658j,  3.05546001e-01-2.06329935j,\n",
       "          7.96781647e-01+0.54473782j, ..., -5.06345862e-01+0.56954715j,\n",
       "         -1.12488510e-01-0.86575752j,  1.29363744e+00-0.42301794j],\n",
       "        ...,\n",
       "        [ 1.60480130e+00+2.44657477j,  8.08142396e-02-1.45825917j,\n",
       "         -1.08379316e+00+0.24187403j, ...,  5.34948012e-01+0.19036978j,\n",
       "          2.87079761e-01-0.84167076j, -2.94255465e-01-1.07491487j],\n",
       "        [ 2.39544983e+00-1.06288208j, -8.60798681e-01-0.56385494j,\n",
       "          7.32005218e-01+1.1418706j , ..., -3.69368694e-01-0.77702032j,\n",
       "         -1.48933969e+00-0.53283772j, -1.61479244e+00+0.59491246j],\n",
       "        [-5.08167822e-01-2.25143296j, -4.95526803e-01-0.12094731j,\n",
       "          7.46297385e-01-1.01989725j, ..., -6.05269935e-01+0.78064672j,\n",
       "         -4.17934473e-01+2.07414711j,  4.81490935e-01+2.06381158j]],\n",
       "\n",
       "       [[-9.62125567e-01+0.j        , -7.17592377e-01+0.j        ,\n",
       "         -4.13095277e-01+0.j        , ..., -3.99618944e+00+0.j        ,\n",
       "         -3.66199515e+00+0.j        , -1.10464593e+00+0.j        ],\n",
       "        [-4.05377143e-01+0.69350413j,  2.05668475e-01+0.70204571j,\n",
       "         -4.78389912e-01+0.22252069j, ..., -6.11150289e-03+3.2981616j ,\n",
       "         -2.42472833e-01+3.43611239j, -1.51553886e+00+0.93598016j],\n",
       "        [ 8.39475890e-02+0.90255681j,  7.09491568e-01-0.7142541j ,\n",
       "         -1.80533715e-01+1.05145362j, ...,  1.45029328e+00-0.13065538j,\n",
       "          2.81142010e+00+0.54891021j,  7.20528618e-01+2.04087565j],\n",
       "        ...,\n",
       "        [-6.25808518e-01+0.62502278j, -1.06619977e-01+0.33032032j,\n",
       "          2.71874715e-01-1.71723774j, ..., -1.41471199e+00-0.43128439j,\n",
       "         -6.85872414e-02+2.14987714j,  7.43143577e-01-1.15875246j],\n",
       "        [-3.86814179e-02+0.76570364j,  2.14736846e-01-0.33514743j,\n",
       "         -1.06025914e+00+0.28205329j, ..., -3.62213291e-01+1.99125825j,\n",
       "          2.03780331e+00+0.12701184j, -2.95716721e-01-0.67959335j],\n",
       "        [ 5.56441569e-01+0.60101403j, -3.12067979e-01+0.16994135j,\n",
       "          3.18581250e-01+0.58018516j, ...,  1.46738952e+00+0.44495464j,\n",
       "          1.04733060e-01-1.80303667j, -3.93767708e-01-0.73832232j]],\n",
       "\n",
       "       [[ 3.07501506e+00+0.j        ,  3.13700939e+00+0.j        ,\n",
       "         -1.90994688e-01+0.j        , ...,  2.93030195e-01+0.j        ,\n",
       "          2.14337436e+00+0.j        ,  1.21989214e+00+0.j        ],\n",
       "        [-1.67860410e+00-2.70406364j,  1.47835280e+00-3.37102311j,\n",
       "          1.08838004e+00+0.7039934j , ..., -6.27558434e-01-0.10280662j,\n",
       "         -7.34488256e-01-2.03822253j,  1.38912568e+00-1.24925263j],\n",
       "        [-1.68226634e+00+2.08147105j, -3.96825453e+00-2.13650498j,\n",
       "          2.18341167e+00-1.20691492j, ...,  3.92330783e-01+0.68994546j,\n",
       "         -1.78078224e+00+1.16533322j, -1.30840668e+00-2.03617174j],\n",
       "        ...,\n",
       "        [-1.29449188e+00+0.6444148j ,  7.21535418e-01+1.41184266j,\n",
       "          1.27354385e+00-0.73845243j, ...,  3.14363170e-01-1.02832193j,\n",
       "         -3.34833798e-01+3.67443761j,  9.24201974e-01-2.86963675j],\n",
       "        [ 1.07781511e+00+1.26740893j,  1.84109065e+00-0.90586122j,\n",
       "         -6.25961410e-01-1.50411141j, ...,  7.07138699e-01+0.22775771j,\n",
       "          3.41737490e+00-0.35256229j, -8.10721411e-01-1.07144504j],\n",
       "        [ 7.77091604e-01-1.56460697j, -6.43118073e-01-2.03212793j,\n",
       "         -1.05674881e+00+0.45127399j, ...,  2.56474341e-01-2.68774043j,\n",
       "         -4.45384166e-01-3.34904566j, -7.20617408e-01-1.09768303j]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.60535810e+00+0.j        ,  4.92543780e+00+0.j        ,\n",
       "          6.10295373e+00+0.j        , ...,  4.94666802e+00+0.j        ,\n",
       "          6.76235843e+00+0.j        ,  5.44934570e+00+0.j        ],\n",
       "        [ 2.14800871e-01-2.21747388j, -1.28923913e+00-4.37768214j,\n",
       "          2.12692913e-01-5.0572642j , ..., -1.27639757e+00-4.33715546j,\n",
       "         -8.71470518e-02-6.03998185j,  9.41760761e-01-4.57024904j],\n",
       "        [-1.80406920e+00-1.01213518j, -2.54982997e+00+3.48515359j,\n",
       "         -2.39070614e+00-2.31173952j, ..., -2.76812089e+00+1.63392936j,\n",
       "         -4.28053465e+00+0.09551452j, -2.59655835e+00-1.41417783j],\n",
       "        ...,\n",
       "        [ 1.48074741e+00+0.70678891j, -4.15338246e-01-0.45530851j,\n",
       "          1.87240138e-01-1.38477509j, ...,  6.66036508e-01+1.35717811j,\n",
       "         -3.09018956e-01-1.10124703j,  8.15757307e-02-0.02953196j],\n",
       "        [ 3.57573866e-01-1.13481817j, -9.74685121e-01-0.31278591j,\n",
       "         -1.41163829e+00+0.28854059j, ...,  9.32366395e-01-0.42523977j,\n",
       "         -7.20174230e-01-0.0378494j ,  6.10800183e-02+0.53790694j],\n",
       "        [-6.37122325e-01-0.09937311j, -4.31028059e-01+1.35229992j,\n",
       "          3.55407189e-01+1.47523291j, ..., -1.46267987e-01-0.3931421j ,\n",
       "         -1.26679650e-01+0.38390868j,  5.32914127e-01-0.20382785j]],\n",
       "\n",
       "       [[ 4.04801319e+00+0.j        ,  3.55183241e+00+0.j        ,\n",
       "          2.53894865e+00+0.j        , ...,  3.63874517e+00+0.j        ,\n",
       "          4.45001669e+00+0.j        ,  4.50397962e+00+0.j        ],\n",
       "        [ 1.24795659e-01-3.35627839j,  2.90042016e-01-3.07628866j,\n",
       "          4.42132889e-01-2.1898548j , ..., -1.84265309e-01-3.04240286j,\n",
       "         -2.86679759e-01-3.77558977j,  1.31861421e-01-3.91494923j],\n",
       "        [-1.76038125e+00+0.09782154j, -1.94811873e+00-0.52610214j,\n",
       "         -1.39484341e+00-0.44307571j, ..., -1.73278412e+00+0.49258955j,\n",
       "         -2.11444735e+00+0.3472973j , -2.63559249e+00-0.35383788j],\n",
       "        ...,\n",
       "        [-1.09431207e+00+0.84374457j,  4.21165929e-01+0.72105691j,\n",
       "          9.55453795e-01-0.87206198j, ..., -7.97957246e-02-0.54868335j,\n",
       "         -1.50311665e+00-1.92267728j, -4.25140816e-01+2.1388001j ],\n",
       "        [ 1.18028992e+00+0.94024188j,  1.45098152e+00-0.62804829j,\n",
       "         -2.80612935e-01-0.49879145j, ..., -2.31554795e+00-0.04302694j,\n",
       "         -2.16187907e+00+1.80157384j,  1.39312852e+00+0.72928084j],\n",
       "        [ 5.48826226e-01-1.59607397j, -4.71192202e-01-1.90389942j,\n",
       "         -1.90604678e-01-0.56177404j, ..., -8.09492153e-02+3.71661883j,\n",
       "          1.27067167e+00+2.38533131j,  6.04819819e-01-0.52709469j]],\n",
       "\n",
       "       [[ 4.49185287e+00+0.j        ,  4.30058005e+00+0.j        ,\n",
       "          2.65954067e+00+0.j        , ...,  0.00000000e+00+0.j        ,\n",
       "          0.00000000e+00+0.j        ,  0.00000000e+00+0.j        ],\n",
       "        [-1.10118274e-01-3.68381958j,  3.42621471e-01-3.87682153j,\n",
       "          7.21703729e-01-2.10782486j, ...,  0.00000000e+00+0.j        ,\n",
       "          0.00000000e+00+0.j        ,  0.00000000e+00+0.j        ],\n",
       "        [-1.83395814e+00+0.34311195j, -2.81125971e+00-0.48678376j,\n",
       "         -8.97208227e-01-1.14657368j, ...,  0.00000000e+00+0.j        ,\n",
       "          0.00000000e+00+0.j        ,  0.00000000e+00+0.j        ],\n",
       "        ...,\n",
       "        [-3.28677603e-01-1.24834799j,  7.07083908e-01+1.4135903j ,\n",
       "         -3.10876526e-01-0.83909706j, ...,  0.00000000e+00+0.j        ,\n",
       "          0.00000000e+00+0.j        ,  0.00000000e+00+0.j        ],\n",
       "        [-1.28860207e-01+0.1583315j ,  1.18485069e+00-0.36062162j,\n",
       "         -3.70667908e-01+0.03453528j, ...,  0.00000000e+00+0.j        ,\n",
       "          0.00000000e+00+0.j        ,  0.00000000e+00+0.j        ],\n",
       "        [ 4.39935260e-02-0.75154617j, -1.48137774e-01-0.96714984j,\n",
       "         -8.13562049e-02-0.24516435j, ...,  0.00000000e+00+0.j        ,\n",
       "          0.00000000e+00+0.j        ,  0.00000000e+00+0.j        ]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027e418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_data.shape,np.std(np.real(noisy_data)),np.mean(np.real(noisy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10595f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12639, 128, 64), (12639, 128, 64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_real = np.real(noisy_data)\n",
    "noisy_img  = np.imag(noisy_data)\n",
    "noisy_real.shape,noisy_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b51bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f12f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_shape = noisy_real.shape\n",
    "# noisy_data_2d = noisy_real.reshape(-1, original_shape[-1])\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler on your data and transform it\n",
    "# scaled_data_2d = scaler.fit_transform(noisy_data_2d)\n",
    "\n",
    "# # Reshape the scaled data back to its original shape\n",
    "# scaled_data = scaled_data_2d.reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ebb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "989464b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trn, X_valid, y_trn, y_valid = train_test_split(noisy_real, clean_real, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43ab835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11375, 128, 64), (1264, 128, 64), (11375, 128, 64), (1264, 128, 64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn.shape, X_valid.shape, y_trn.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad3837",
   "metadata": {},
   "source": [
    "## Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55c6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa5ea6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Compile the model (choose appropriate loss and optimizer)\n",
    "# # Set the Adam optimizer with a custom learning rate\n",
    "\n",
    "# initial_learning_rate = 0.0001  # Define your initial learning rate 0.0001  best\n",
    "# adam_optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer=adam_optimizer,metrics=\"accuracy\")\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_trn,y_trn , epochs=10000, batch_size=64,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdd4c308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 33s 111ms/step - loss: 0.3775 - accuracy: 0.1014 - val_loss: 0.3834 - val_accuracy: 0.0842\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3375 - accuracy: 0.1014 - val_loss: 0.3405 - val_accuracy: 0.0842\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.3035 - accuracy: 0.1014 - val_loss: 0.2882 - val_accuracy: 0.0842\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2751 - accuracy: 0.1014 - val_loss: 0.2495 - val_accuracy: 0.0842\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2546 - accuracy: 0.1014 - val_loss: 0.2393 - val_accuracy: 0.0842\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2375 - accuracy: 0.1014 - val_loss: 0.2242 - val_accuracy: 0.0842\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2251 - accuracy: 0.1014 - val_loss: 0.2187 - val_accuracy: 0.0842\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2156 - accuracy: 0.1014 - val_loss: 0.2071 - val_accuracy: 0.0842\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2099 - accuracy: 0.1014 - val_loss: 0.2069 - val_accuracy: 0.0842\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2022 - accuracy: 0.1014 - val_loss: 0.1995 - val_accuracy: 0.0842\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1962 - accuracy: 0.1014 - val_loss: 0.1925 - val_accuracy: 0.0842\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1910 - accuracy: 0.1014 - val_loss: 0.1856 - val_accuracy: 0.0842\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1871 - accuracy: 0.1014 - val_loss: 0.1839 - val_accuracy: 0.0842\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1826 - accuracy: 0.1014 - val_loss: 0.1733 - val_accuracy: 0.0842\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1782 - accuracy: 0.1014 - val_loss: 0.1744 - val_accuracy: 0.0842\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1755 - accuracy: 0.1014 - val_loss: 0.1697 - val_accuracy: 0.0842\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1720 - accuracy: 0.1014 - val_loss: 0.1667 - val_accuracy: 0.0842\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1687 - accuracy: 0.1014 - val_loss: 0.1613 - val_accuracy: 0.0842\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1663 - accuracy: 0.1014 - val_loss: 0.1707 - val_accuracy: 0.0842\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1631 - accuracy: 0.1014 - val_loss: 0.1598 - val_accuracy: 0.0842\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1612 - accuracy: 0.1014 - val_loss: 0.1554 - val_accuracy: 0.0842\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1594 - accuracy: 0.1014 - val_loss: 0.1542 - val_accuracy: 0.0842\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1561 - accuracy: 0.1014 - val_loss: 0.1528 - val_accuracy: 0.0842\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1544 - accuracy: 0.1014 - val_loss: 0.1498 - val_accuracy: 0.0842\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1526 - accuracy: 0.1014 - val_loss: 0.1552 - val_accuracy: 0.0842\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1508 - accuracy: 0.1014 - val_loss: 0.1488 - val_accuracy: 0.0842\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1488 - accuracy: 0.1014 - val_loss: 0.1489 - val_accuracy: 0.0842\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1473 - accuracy: 0.1014 - val_loss: 0.1416 - val_accuracy: 0.0842\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1454 - accuracy: 0.1014 - val_loss: 0.1405 - val_accuracy: 0.0842\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1444 - accuracy: 0.1014 - val_loss: 0.1438 - val_accuracy: 0.0842\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1433 - accuracy: 0.1014 - val_loss: 0.1413 - val_accuracy: 0.0842\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1422 - accuracy: 0.1014 - val_loss: 0.1388 - val_accuracy: 0.0842\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1409 - accuracy: 0.1014 - val_loss: 0.1385 - val_accuracy: 0.0842\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1400 - accuracy: 0.1014 - val_loss: 0.1369 - val_accuracy: 0.0842\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1391 - accuracy: 0.1014 - val_loss: 0.1363 - val_accuracy: 0.0842\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1387 - accuracy: 0.1014 - val_loss: 0.1346 - val_accuracy: 0.0842\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1370 - accuracy: 0.1014 - val_loss: 0.1368 - val_accuracy: 0.0842\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1359 - accuracy: 0.1014 - val_loss: 0.1338 - val_accuracy: 0.0842\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1354 - accuracy: 0.1014 - val_loss: 0.1348 - val_accuracy: 0.0842\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1349 - accuracy: 0.1014 - val_loss: 0.1320 - val_accuracy: 0.0842\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1340 - accuracy: 0.1014 - val_loss: 0.1366 - val_accuracy: 0.0842\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1335 - accuracy: 0.1014 - val_loss: 0.1308 - val_accuracy: 0.0842\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1324 - accuracy: 0.1014 - val_loss: 0.1307 - val_accuracy: 0.0842\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1321 - accuracy: 0.1014 - val_loss: 0.1296 - val_accuracy: 0.0842\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1317 - accuracy: 0.1014 - val_loss: 0.1329 - val_accuracy: 0.0842\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1310 - accuracy: 0.1014 - val_loss: 0.1304 - val_accuracy: 0.0842\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1309 - accuracy: 0.1014 - val_loss: 0.1301 - val_accuracy: 0.0842\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1302 - accuracy: 0.1014 - val_loss: 0.1271 - val_accuracy: 0.0842\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1301 - accuracy: 0.1014 - val_loss: 0.1282 - val_accuracy: 0.0842\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1296 - accuracy: 0.1014 - val_loss: 0.1273 - val_accuracy: 0.0842\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1297 - accuracy: 0.1014 - val_loss: 0.1277 - val_accuracy: 0.0842\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1285 - accuracy: 0.1014 - val_loss: 0.1259 - val_accuracy: 0.0842\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1285 - accuracy: 0.1014 - val_loss: 0.1267 - val_accuracy: 0.0842\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1282 - accuracy: 0.1014 - val_loss: 0.1270 - val_accuracy: 0.0842\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1280 - accuracy: 0.1014 - val_loss: 0.1257 - val_accuracy: 0.0842\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1275 - accuracy: 0.1014 - val_loss: 0.1266 - val_accuracy: 0.0842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1274 - accuracy: 0.1014 - val_loss: 0.1249 - val_accuracy: 0.0842\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1263 - accuracy: 0.1014 - val_loss: 0.1261 - val_accuracy: 0.0842\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1260 - accuracy: 0.1014 - val_loss: 0.1231 - val_accuracy: 0.0842\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1260 - accuracy: 0.1014 - val_loss: 0.1247 - val_accuracy: 0.0842\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1257 - accuracy: 0.1014 - val_loss: 0.1241 - val_accuracy: 0.0842\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1253 - accuracy: 0.1014 - val_loss: 0.1232 - val_accuracy: 0.0842\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1255 - accuracy: 0.1014 - val_loss: 0.1264 - val_accuracy: 0.0842\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1254 - accuracy: 0.1014 - val_loss: 0.1233 - val_accuracy: 0.0842\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1249 - accuracy: 0.1014 - val_loss: 0.1212 - val_accuracy: 0.0842\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1248 - accuracy: 0.1014 - val_loss: 0.1239 - val_accuracy: 0.0842\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1257 - accuracy: 0.1014 - val_loss: 0.1237 - val_accuracy: 0.0842\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1244 - accuracy: 0.1014 - val_loss: 0.1218 - val_accuracy: 0.0842\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1239 - accuracy: 0.1014 - val_loss: 0.1229 - val_accuracy: 0.0842\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1245 - accuracy: 0.1014 - val_loss: 0.1229 - val_accuracy: 0.0842\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1241 - accuracy: 0.1014 - val_loss: 0.1236 - val_accuracy: 0.0842\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1239 - accuracy: 0.1014 - val_loss: 0.1245 - val_accuracy: 0.0842\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1244 - accuracy: 0.1014 - val_loss: 0.1245 - val_accuracy: 0.0842\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1239 - accuracy: 0.1014 - val_loss: 0.1229 - val_accuracy: 0.0842\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1232 - accuracy: 0.1014 - val_loss: 0.1223 - val_accuracy: 0.0842\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1229 - accuracy: 0.1014 - val_loss: 0.1234 - val_accuracy: 0.0842\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1226 - accuracy: 0.1014 - val_loss: 0.1210 - val_accuracy: 0.0842\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1227 - accuracy: 0.1014 - val_loss: 0.1217 - val_accuracy: 0.0842\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1221 - accuracy: 0.1014 - val_loss: 0.1213 - val_accuracy: 0.0842\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1220 - accuracy: 0.1014 - val_loss: 0.1219 - val_accuracy: 0.0842\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1222 - accuracy: 0.1014 - val_loss: 0.1214 - val_accuracy: 0.0842\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1217 - accuracy: 0.1014 - val_loss: 0.1208 - val_accuracy: 0.0842\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1216 - accuracy: 0.1014 - val_loss: 0.1217 - val_accuracy: 0.0842\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1214 - accuracy: 0.1014 - val_loss: 0.1216 - val_accuracy: 0.0842\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1213 - accuracy: 0.1014 - val_loss: 0.1206 - val_accuracy: 0.0842\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1222 - accuracy: 0.1014 - val_loss: 0.1203 - val_accuracy: 0.0842\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1217 - accuracy: 0.1014 - val_loss: 0.1222 - val_accuracy: 0.0842\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1217 - accuracy: 0.1014 - val_loss: 0.1208 - val_accuracy: 0.0842\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1219 - accuracy: 0.1014 - val_loss: 0.1231 - val_accuracy: 0.0842\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1215 - accuracy: 0.1014 - val_loss: 0.1199 - val_accuracy: 0.0842\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1208 - accuracy: 0.1014 - val_loss: 0.1202 - val_accuracy: 0.0842\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1213 - accuracy: 0.1014 - val_loss: 0.1210 - val_accuracy: 0.0842\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1207 - accuracy: 0.1014 - val_loss: 0.1189 - val_accuracy: 0.0842\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1203 - accuracy: 0.1014 - val_loss: 0.1201 - val_accuracy: 0.0842\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1206 - accuracy: 0.1014 - val_loss: 0.1203 - val_accuracy: 0.0842\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1200 - accuracy: 0.1014 - val_loss: 0.1202 - val_accuracy: 0.0842\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1198 - accuracy: 0.1014 - val_loss: 0.1192 - val_accuracy: 0.0842\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1206 - accuracy: 0.1014 - val_loss: 0.1195 - val_accuracy: 0.0842\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1203 - accuracy: 0.1014 - val_loss: 0.1208 - val_accuracy: 0.0842\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1200 - accuracy: 0.1014 - val_loss: 0.1193 - val_accuracy: 0.0842\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1195 - accuracy: 0.1014 - val_loss: 0.1208 - val_accuracy: 0.0842\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1198 - accuracy: 0.1014 - val_loss: 0.1199 - val_accuracy: 0.0842\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1196 - accuracy: 0.1014 - val_loss: 0.1183 - val_accuracy: 0.0842\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1204 - accuracy: 0.1014 - val_loss: 0.1193 - val_accuracy: 0.0842\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1198 - accuracy: 0.1014 - val_loss: 0.1179 - val_accuracy: 0.0842\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1196 - accuracy: 0.1014 - val_loss: 0.1188 - val_accuracy: 0.0842\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1194 - accuracy: 0.1014 - val_loss: 0.1192 - val_accuracy: 0.0842\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1190 - accuracy: 0.1014 - val_loss: 0.1185 - val_accuracy: 0.0842\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1188 - accuracy: 0.1014 - val_loss: 0.1170 - val_accuracy: 0.0842\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1188 - accuracy: 0.1014 - val_loss: 0.1177 - val_accuracy: 0.0842\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1192 - accuracy: 0.1014 - val_loss: 0.1170 - val_accuracy: 0.0842\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1188 - accuracy: 0.1014 - val_loss: 0.1181 - val_accuracy: 0.0842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1187 - accuracy: 0.1014 - val_loss: 0.1172 - val_accuracy: 0.0842\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1188 - accuracy: 0.1014 - val_loss: 0.1195 - val_accuracy: 0.0842\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1186 - accuracy: 0.1014 - val_loss: 0.1170 - val_accuracy: 0.0842\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1182 - accuracy: 0.1014 - val_loss: 0.1172 - val_accuracy: 0.0842\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1181 - accuracy: 0.1014 - val_loss: 0.1175 - val_accuracy: 0.0842\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1184 - accuracy: 0.1014 - val_loss: 0.1170 - val_accuracy: 0.0842\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1181 - accuracy: 0.1014 - val_loss: 0.1177 - val_accuracy: 0.0842\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1182 - accuracy: 0.1014 - val_loss: 0.1180 - val_accuracy: 0.0842\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1184 - accuracy: 0.1014 - val_loss: 0.1183 - val_accuracy: 0.0842\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1179 - accuracy: 0.1014 - val_loss: 0.1174 - val_accuracy: 0.0842\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1178 - accuracy: 0.1014 - val_loss: 0.1180 - val_accuracy: 0.0842\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1178 - accuracy: 0.1014 - val_loss: 0.1182 - val_accuracy: 0.0842\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1192 - accuracy: 0.1014 - val_loss: 0.1184 - val_accuracy: 0.0842\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1183 - accuracy: 0.1014 - val_loss: 0.1174 - val_accuracy: 0.0842\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1191 - accuracy: 0.1014 - val_loss: 0.1182 - val_accuracy: 0.0842\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1186 - accuracy: 0.1014 - val_loss: 0.1179 - val_accuracy: 0.0842\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1180 - accuracy: 0.1014 - val_loss: 0.1170 - val_accuracy: 0.0842\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1175 - accuracy: 0.1014 - val_loss: 0.1175 - val_accuracy: 0.0842\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1173 - accuracy: 0.1014 - val_loss: 0.1177 - val_accuracy: 0.0842\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1172 - accuracy: 0.1014 - val_loss: 0.1190 - val_accuracy: 0.0842\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1176 - accuracy: 0.1014 - val_loss: 0.1173 - val_accuracy: 0.0842\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1176 - accuracy: 0.1014 - val_loss: 0.1185 - val_accuracy: 0.0842\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1176 - accuracy: 0.1014 - val_loss: 0.1175 - val_accuracy: 0.0842\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1174 - accuracy: 0.1014 - val_loss: 0.1166 - val_accuracy: 0.0842\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1176 - accuracy: 0.1014 - val_loss: 0.1188 - val_accuracy: 0.0842\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1172 - accuracy: 0.1014 - val_loss: 0.1173 - val_accuracy: 0.0842\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1169 - accuracy: 0.1014 - val_loss: 0.1175 - val_accuracy: 0.0842\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1168 - accuracy: 0.1014 - val_loss: 0.1195 - val_accuracy: 0.0842\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1169 - accuracy: 0.1014 - val_loss: 0.1188 - val_accuracy: 0.0842\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1166 - accuracy: 0.1014 - val_loss: 0.1162 - val_accuracy: 0.0842\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1165 - accuracy: 0.1014 - val_loss: 0.1169 - val_accuracy: 0.0842\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1164 - accuracy: 0.1014 - val_loss: 0.1165 - val_accuracy: 0.0842\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1165 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1163 - accuracy: 0.1014 - val_loss: 0.1164 - val_accuracy: 0.0842\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1168 - accuracy: 0.1014 - val_loss: 0.1178 - val_accuracy: 0.0842\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1166 - accuracy: 0.1014 - val_loss: 0.1170 - val_accuracy: 0.0842\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1167 - accuracy: 0.1014 - val_loss: 0.1180 - val_accuracy: 0.0842\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1170 - accuracy: 0.1014 - val_loss: 0.1185 - val_accuracy: 0.0842\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1164 - accuracy: 0.1014 - val_loss: 0.1168 - val_accuracy: 0.0842\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1162 - accuracy: 0.1014 - val_loss: 0.1162 - val_accuracy: 0.0842\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1160 - accuracy: 0.1014 - val_loss: 0.1158 - val_accuracy: 0.0842\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1159 - accuracy: 0.1014 - val_loss: 0.1192 - val_accuracy: 0.0842\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1160 - accuracy: 0.1014 - val_loss: 0.1160 - val_accuracy: 0.0842\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1158 - accuracy: 0.1014 - val_loss: 0.1152 - val_accuracy: 0.0842\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1157 - accuracy: 0.1014 - val_loss: 0.1150 - val_accuracy: 0.0842\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1158 - accuracy: 0.1014 - val_loss: 0.1146 - val_accuracy: 0.0842\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1158 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1157 - accuracy: 0.1014 - val_loss: 0.1161 - val_accuracy: 0.0842\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1155 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1154 - accuracy: 0.1014 - val_loss: 0.1150 - val_accuracy: 0.0842\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1153 - accuracy: 0.1014 - val_loss: 0.1158 - val_accuracy: 0.0842\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1152 - accuracy: 0.1014 - val_loss: 0.1152 - val_accuracy: 0.0842\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1154 - accuracy: 0.1014 - val_loss: 0.1157 - val_accuracy: 0.0842\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1173 - accuracy: 0.1014 - val_loss: 0.1167 - val_accuracy: 0.0842\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1161 - accuracy: 0.1014 - val_loss: 0.1158 - val_accuracy: 0.0842\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1156 - accuracy: 0.1014 - val_loss: 0.1178 - val_accuracy: 0.0842\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1176 - accuracy: 0.1014 - val_loss: 0.1172 - val_accuracy: 0.0842\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1169 - accuracy: 0.1014 - val_loss: 0.1160 - val_accuracy: 0.0842\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1157 - accuracy: 0.1014 - val_loss: 0.1158 - val_accuracy: 0.0842\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1154 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1152 - accuracy: 0.1014 - val_loss: 0.1155 - val_accuracy: 0.0842\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1150 - accuracy: 0.1014 - val_loss: 0.1158 - val_accuracy: 0.0842\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1149 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1148 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1148 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1148 - accuracy: 0.1014 - val_loss: 0.1153 - val_accuracy: 0.0842\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1147 - accuracy: 0.1014 - val_loss: 0.1148 - val_accuracy: 0.0842\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1147 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1147 - accuracy: 0.1014 - val_loss: 0.1144 - val_accuracy: 0.0842\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1146 - accuracy: 0.1014 - val_loss: 0.1146 - val_accuracy: 0.0842\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1145 - accuracy: 0.1014 - val_loss: 0.1154 - val_accuracy: 0.0842\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1144 - accuracy: 0.1014 - val_loss: 0.1156 - val_accuracy: 0.0842\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1145 - accuracy: 0.1014 - val_loss: 0.1156 - val_accuracy: 0.0842\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1144 - accuracy: 0.1014 - val_loss: 0.1150 - val_accuracy: 0.0842\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1143 - accuracy: 0.1014 - val_loss: 0.1148 - val_accuracy: 0.0842\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1142 - accuracy: 0.1014 - val_loss: 0.1152 - val_accuracy: 0.0842\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1142 - accuracy: 0.1014 - val_loss: 0.1149 - val_accuracy: 0.0842\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1142 - accuracy: 0.1014 - val_loss: 0.1145 - val_accuracy: 0.0842\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1141 - accuracy: 0.1014 - val_loss: 0.1151 - val_accuracy: 0.0842\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1146 - accuracy: 0.1014 - val_loss: 0.1196 - val_accuracy: 0.0842\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1156 - accuracy: 0.1014 - val_loss: 0.1146 - val_accuracy: 0.0842\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1146 - accuracy: 0.1014 - val_loss: 0.1147 - val_accuracy: 0.0842\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1143 - accuracy: 0.1014 - val_loss: 0.1149 - val_accuracy: 0.0842\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1141 - accuracy: 0.1014 - val_loss: 0.1149 - val_accuracy: 0.0842\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1141 - accuracy: 0.1014 - val_loss: 0.1146 - val_accuracy: 0.0842\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1139 - accuracy: 0.1014 - val_loss: 0.1145 - val_accuracy: 0.0842\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1137 - accuracy: 0.1014 - val_loss: 0.1143 - val_accuracy: 0.0842\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1140 - accuracy: 0.1014 - val_loss: 0.1148 - val_accuracy: 0.0842\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1138 - accuracy: 0.1014 - val_loss: 0.1145 - val_accuracy: 0.0842\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1136 - accuracy: 0.1014 - val_loss: 0.1144 - val_accuracy: 0.0842\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1136 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1135 - accuracy: 0.1014 - val_loss: 0.1139 - val_accuracy: 0.0842\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1135 - accuracy: 0.1014 - val_loss: 0.1143 - val_accuracy: 0.0842\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1138 - accuracy: 0.1014 - val_loss: 0.1165 - val_accuracy: 0.0842\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1145 - accuracy: 0.1014 - val_loss: 0.1142 - val_accuracy: 0.0842\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1139 - accuracy: 0.1014 - val_loss: 0.1168 - val_accuracy: 0.0842\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1151 - accuracy: 0.1014 - val_loss: 0.1164 - val_accuracy: 0.0842\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1150 - accuracy: 0.1014 - val_loss: 0.1225 - val_accuracy: 0.0842\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1166 - accuracy: 0.1014 - val_loss: 0.1152 - val_accuracy: 0.0842\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1142 - accuracy: 0.1014 - val_loss: 0.1145 - val_accuracy: 0.0842\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1138 - accuracy: 0.1014 - val_loss: 0.1144 - val_accuracy: 0.0842\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1136 - accuracy: 0.1014 - val_loss: 0.1142 - val_accuracy: 0.0842\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1135 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1134 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1133 - accuracy: 0.1014 - val_loss: 0.1135 - val_accuracy: 0.0842\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1132 - accuracy: 0.1014 - val_loss: 0.1139 - val_accuracy: 0.0842\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1132 - accuracy: 0.1014 - val_loss: 0.1141 - val_accuracy: 0.0842\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1131 - accuracy: 0.1014 - val_loss: 0.1140 - val_accuracy: 0.0842\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1131 - accuracy: 0.1014 - val_loss: 0.1134 - val_accuracy: 0.0842\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1131 - accuracy: 0.1014 - val_loss: 0.1144 - val_accuracy: 0.0842\n",
      "Epoch 223/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1132 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1131 - accuracy: 0.1014 - val_loss: 0.1141 - val_accuracy: 0.0842\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1130 - accuracy: 0.1014 - val_loss: 0.1134 - val_accuracy: 0.0842\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1129 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1129 - accuracy: 0.1014 - val_loss: 0.1135 - val_accuracy: 0.0842\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1129 - accuracy: 0.1014 - val_loss: 0.1133 - val_accuracy: 0.0842\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1129 - accuracy: 0.1014 - val_loss: 0.1136 - val_accuracy: 0.0842\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1128 - accuracy: 0.1014 - val_loss: 0.1135 - val_accuracy: 0.0842\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1128 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1127 - accuracy: 0.1014 - val_loss: 0.1134 - val_accuracy: 0.0842\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1127 - accuracy: 0.1014 - val_loss: 0.1137 - val_accuracy: 0.0842\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1127 - accuracy: 0.1014 - val_loss: 0.1133 - val_accuracy: 0.0842\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1126 - accuracy: 0.1014 - val_loss: 0.1131 - val_accuracy: 0.0842\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1126 - accuracy: 0.1014 - val_loss: 0.1134 - val_accuracy: 0.0842\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1125 - accuracy: 0.1014 - val_loss: 0.1128 - val_accuracy: 0.0842\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1125 - accuracy: 0.1014 - val_loss: 0.1131 - val_accuracy: 0.0842\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1126 - accuracy: 0.1014 - val_loss: 0.1144 - val_accuracy: 0.0842\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1129 - accuracy: 0.1014 - val_loss: 0.1135 - val_accuracy: 0.0842\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1125 - accuracy: 0.1014 - val_loss: 0.1132 - val_accuracy: 0.0842\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1124 - accuracy: 0.1014 - val_loss: 0.1133 - val_accuracy: 0.0842\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1124 - accuracy: 0.1014 - val_loss: 0.1129 - val_accuracy: 0.0842\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1125 - accuracy: 0.1014 - val_loss: 0.1133 - val_accuracy: 0.0842\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1123 - accuracy: 0.1014 - val_loss: 0.1124 - val_accuracy: 0.0842\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1130 - accuracy: 0.1014 - val_loss: 0.1149 - val_accuracy: 0.0842\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1127 - accuracy: 0.1014 - val_loss: 0.1131 - val_accuracy: 0.0842\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1124 - accuracy: 0.1014 - val_loss: 0.1129 - val_accuracy: 0.0842\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1122 - accuracy: 0.1014 - val_loss: 0.1129 - val_accuracy: 0.0842\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1122 - accuracy: 0.1014 - val_loss: 0.1131 - val_accuracy: 0.0842\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1121 - accuracy: 0.1014 - val_loss: 0.1128 - val_accuracy: 0.0842\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1121 - accuracy: 0.1014 - val_loss: 0.1131 - val_accuracy: 0.0842\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1120 - accuracy: 0.1014 - val_loss: 0.1128 - val_accuracy: 0.0842\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1121 - accuracy: 0.1014 - val_loss: 0.1130 - val_accuracy: 0.0842\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1120 - accuracy: 0.1014 - val_loss: 0.1133 - val_accuracy: 0.0842\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1120 - accuracy: 0.1014 - val_loss: 0.1127 - val_accuracy: 0.0842\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1120 - accuracy: 0.1014 - val_loss: 0.1125 - val_accuracy: 0.0842\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1120 - accuracy: 0.1014 - val_loss: 0.1125 - val_accuracy: 0.0842\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1119 - accuracy: 0.1014 - val_loss: 0.1129 - val_accuracy: 0.0842\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1119 - accuracy: 0.1014 - val_loss: 0.1131 - val_accuracy: 0.0842\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1118 - accuracy: 0.1014 - val_loss: 0.1126 - val_accuracy: 0.0842\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1119 - accuracy: 0.1014 - val_loss: 0.1128 - val_accuracy: 0.0842\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1118 - accuracy: 0.1014 - val_loss: 0.1126 - val_accuracy: 0.0842\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1118 - accuracy: 0.1014 - val_loss: 0.1119 - val_accuracy: 0.0842\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1117 - accuracy: 0.1014 - val_loss: 0.1125 - val_accuracy: 0.0842\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1117 - accuracy: 0.1014 - val_loss: 0.1124 - val_accuracy: 0.0842\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1117 - accuracy: 0.1014 - val_loss: 0.1123 - val_accuracy: 0.0842\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1116 - accuracy: 0.1014 - val_loss: 0.1126 - val_accuracy: 0.0842\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1116 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1116 - accuracy: 0.1014 - val_loss: 0.1124 - val_accuracy: 0.0842\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1116 - accuracy: 0.1014 - val_loss: 0.1123 - val_accuracy: 0.0842\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1117 - accuracy: 0.1014 - val_loss: 0.1139 - val_accuracy: 0.0842\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1117 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1116 - accuracy: 0.1014 - val_loss: 0.1126 - val_accuracy: 0.0842\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1115 - accuracy: 0.1014 - val_loss: 0.1123 - val_accuracy: 0.0842\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1114 - accuracy: 0.1014 - val_loss: 0.1122 - val_accuracy: 0.0842\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1114 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1114 - accuracy: 0.1014 - val_loss: 0.1121 - val_accuracy: 0.0842\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1113 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1114 - accuracy: 0.1014 - val_loss: 0.1122 - val_accuracy: 0.0842\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1114 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1114 - accuracy: 0.1014 - val_loss: 0.1116 - val_accuracy: 0.0842\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1113 - accuracy: 0.1014 - val_loss: 0.1121 - val_accuracy: 0.0842\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1113 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1112 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1112 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1112 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1111 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1111 - accuracy: 0.1014 - val_loss: 0.1116 - val_accuracy: 0.0842\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1111 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1111 - accuracy: 0.1014 - val_loss: 0.1113 - val_accuracy: 0.0842\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1111 - accuracy: 0.1014 - val_loss: 0.1121 - val_accuracy: 0.0842\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1120 - val_accuracy: 0.0842\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1114 - val_accuracy: 0.0842\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1114 - val_accuracy: 0.0842\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1114 - val_accuracy: 0.0842\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1114 - val_accuracy: 0.0842\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1110 - accuracy: 0.1014 - val_loss: 0.1113 - val_accuracy: 0.0842\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1109 - accuracy: 0.1014 - val_loss: 0.1118 - val_accuracy: 0.0842\n",
      "Training Fold 2\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.1155 - accuracy: 0.0989 - val_loss: 0.1109 - val_accuracy: 0.1061\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1129 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1119 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1111 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1109 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1107 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1106 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1105 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1104 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1103 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1103 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1103 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1103 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1102 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1102 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1102 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1102 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1102 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1069 - val_accuracy: 0.1061\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1100 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1100 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1100 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1100 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1070 - val_accuracy: 0.1061\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1079 - val_accuracy: 0.1061\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1101 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1098 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1097 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1097 - accuracy: 0.0989 - val_loss: 0.1071 - val_accuracy: 0.1061\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1097 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1097 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1097 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1072 - val_accuracy: 0.1061\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1074 - val_accuracy: 0.1061\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1074 - val_accuracy: 0.1061\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1074 - val_accuracy: 0.1061\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1073 - val_accuracy: 0.1061\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1075 - val_accuracy: 0.1061\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1075 - val_accuracy: 0.1061\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1075 - val_accuracy: 0.1061\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1096 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1105 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1108 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1098 - accuracy: 0.0989 - val_loss: 0.1078 - val_accuracy: 0.1061\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1095 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1094 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1075 - val_accuracy: 0.1061\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1075 - val_accuracy: 0.1061\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1075 - val_accuracy: 0.1061\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1076 - val_accuracy: 0.1061\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1092 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1078 - val_accuracy: 0.1061\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1077 - val_accuracy: 0.1061\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1118 - accuracy: 0.0989 - val_loss: 0.1131 - val_accuracy: 0.1061\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1112 - accuracy: 0.0989 - val_loss: 0.1093 - val_accuracy: 0.1061\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1099 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1094 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1093 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1091 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1090 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1090 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1090 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1079 - val_accuracy: 0.1061\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1079 - val_accuracy: 0.1061\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1079 - val_accuracy: 0.1061\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1080 - val_accuracy: 0.1061\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1089 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1088 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 18s 98ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1081 - val_accuracy: 0.1061\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1086 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1082 - val_accuracy: 0.1061\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1092 - val_accuracy: 0.1061\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1087 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1083 - val_accuracy: 0.1061\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 199/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1084 - val_accuracy: 0.1061\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1085 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1085 - val_accuracy: 0.1061\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1092 - val_accuracy: 0.1061\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1084 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 22s 123ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1083 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 24s 134ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1086 - val_accuracy: 0.1061\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1082 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 24s 134ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1087 - val_accuracy: 0.1061\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1090 - val_accuracy: 0.1061\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1088 - val_accuracy: 0.1061\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1090 - val_accuracy: 0.1061\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1081 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1090 - val_accuracy: 0.1061\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1091 - val_accuracy: 0.1061\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1090 - val_accuracy: 0.1061\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1090 - val_accuracy: 0.1061\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1091 - val_accuracy: 0.1061\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1089 - val_accuracy: 0.1061\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1091 - val_accuracy: 0.1061\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1080 - accuracy: 0.0989 - val_loss: 0.1090 - val_accuracy: 0.1061\n",
      "Training Fold 3\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1094 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1088 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1082 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1078 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1076 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1075 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1075 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1104 - val_accuracy: 0.1029\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1105 - val_accuracy: 0.1029\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1074 - accuracy: 0.0993 - val_loss: 0.1106 - val_accuracy: 0.1029\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1107 - val_accuracy: 0.1029\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1108 - val_accuracy: 0.1029\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1109 - val_accuracy: 0.1029\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1110 - val_accuracy: 0.1029\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1111 - val_accuracy: 0.1029\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1112 - val_accuracy: 0.1029\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1113 - val_accuracy: 0.1029\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1114 - val_accuracy: 0.1029\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1115 - val_accuracy: 0.1029\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1116 - val_accuracy: 0.1029\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1117 - val_accuracy: 0.1029\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1118 - val_accuracy: 0.1029\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1119 - val_accuracy: 0.1029\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1120 - val_accuracy: 0.1029\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1121 - val_accuracy: 0.1029\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1122 - val_accuracy: 0.1029\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1123 - val_accuracy: 0.1029\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1124 - val_accuracy: 0.1029\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1125 - val_accuracy: 0.1029\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1127 - val_accuracy: 0.1029\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0993 - val_loss: 0.1126 - val_accuracy: 0.1029\n",
      "Training Fold 4\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1088 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1087 - accuracy: 0.0982 - val_loss: 0.1079 - val_accuracy: 0.1128\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1079 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1075 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1071 - val_accuracy: 0.1128\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1071 - val_accuracy: 0.1128\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1071 - val_accuracy: 0.1128\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1071 - val_accuracy: 0.1128\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1072 - val_accuracy: 0.1128\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1073 - val_accuracy: 0.1128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1074 - val_accuracy: 0.1128\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1075 - val_accuracy: 0.1128\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1076 - val_accuracy: 0.1128\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1077 - val_accuracy: 0.1128\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1078 - val_accuracy: 0.1128\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1079 - val_accuracy: 0.1128\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1079 - val_accuracy: 0.1128\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1075 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1075 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0982 - val_loss: 0.1079 - val_accuracy: 0.1128\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1074 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1072 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1080 - val_accuracy: 0.1128\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1081 - val_accuracy: 0.1128\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1082 - val_accuracy: 0.1128\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1083 - val_accuracy: 0.1128\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 207/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1084 - val_accuracy: 0.1128\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1085 - val_accuracy: 0.1128\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1086 - val_accuracy: 0.1128\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1087 - val_accuracy: 0.1128\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1090 - val_accuracy: 0.1128\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1088 - val_accuracy: 0.1128\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0982 - val_loss: 0.1089 - val_accuracy: 0.1128\n",
      "Training Fold 5\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1072 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1073 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1071 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1068 - val_accuracy: 0.1041\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1069 - val_accuracy: 0.1041\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1070 - val_accuracy: 0.1041\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1071 - val_accuracy: 0.1041\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1072 - val_accuracy: 0.1041\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1073 - val_accuracy: 0.1041\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1074 - val_accuracy: 0.1041\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1069 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1071 - accuracy: 0.0991 - val_loss: 0.1085 - val_accuracy: 0.1041\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1073 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1070 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1075 - val_accuracy: 0.1041\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1068 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1076 - val_accuracy: 0.1041\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1077 - val_accuracy: 0.1041\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 183/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1078 - val_accuracy: 0.1041\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1079 - val_accuracy: 0.1041\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1080 - val_accuracy: 0.1041\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1081 - val_accuracy: 0.1041\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1083 - val_accuracy: 0.1041\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0991 - val_loss: 0.1082 - val_accuracy: 0.1041\n",
      "Training Fold 6\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1067 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1083 - val_accuracy: 0.1012\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1084 - val_accuracy: 0.1012\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 21s 120ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1085 - val_accuracy: 0.1012\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1086 - val_accuracy: 0.1012\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1087 - val_accuracy: 0.1012\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1088 - val_accuracy: 0.1012\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1089 - val_accuracy: 0.1012\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1090 - val_accuracy: 0.1012\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 215/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1091 - val_accuracy: 0.1012\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1092 - val_accuracy: 0.1012\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1095 - val_accuracy: 0.1012\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1093 - val_accuracy: 0.1012\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1096 - val_accuracy: 0.1012\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0995 - val_loss: 0.1094 - val_accuracy: 0.1012\n",
      "Training Fold 7\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1087 - val_accuracy: 0.0918\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1088 - val_accuracy: 0.0918\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1089 - val_accuracy: 0.0918\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1090 - val_accuracy: 0.0918\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1091 - val_accuracy: 0.0918\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1092 - val_accuracy: 0.0918\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1093 - val_accuracy: 0.0918\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 191/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1094 - val_accuracy: 0.0918\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1063 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1095 - val_accuracy: 0.0918\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1096 - val_accuracy: 0.0918\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1097 - val_accuracy: 0.0918\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1062 - accuracy: 0.1005 - val_loss: 0.1099 - val_accuracy: 0.0918\n",
      "Training Fold 8\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1104 - val_accuracy: 0.0954\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1062 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1105 - val_accuracy: 0.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1106 - val_accuracy: 0.0954\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1107 - val_accuracy: 0.0954\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1063 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1061 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1108 - val_accuracy: 0.0954\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1109 - val_accuracy: 0.0954\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1110 - val_accuracy: 0.0954\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1111 - val_accuracy: 0.0954\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1112 - val_accuracy: 0.0954\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1001 - val_loss: 0.1113 - val_accuracy: 0.0954\n",
      "Training Fold 9\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1066 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1066 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1066 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 8/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1057 - val_accuracy: 0.1050\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 22s 123ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 22s 125ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1058 - val_accuracy: 0.1050\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 64/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1059 - val_accuracy: 0.1050\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1060 - val_accuracy: 0.1050\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1061 - val_accuracy: 0.1050\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 174/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 198/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1062 - val_accuracy: 0.1050\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1065 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1063 - val_accuracy: 0.1050\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 284/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1064 - val_accuracy: 0.1050\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1064 - accuracy: 0.0990 - val_loss: 0.1065 - val_accuracy: 0.1050\n",
      "Training Fold 10\n",
      "Epoch 1/300\n",
      "178/178 [==============================] - 25s 138ms/step - loss: 0.1060 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 2/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1060 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 3/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1060 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 4/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1104 - val_accuracy: 0.0928\n",
      "Epoch 5/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1104 - val_accuracy: 0.0928\n",
      "Epoch 6/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1104 - val_accuracy: 0.0928\n",
      "Epoch 7/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 9/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 10/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 11/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 12/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 13/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 14/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 15/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 16/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 17/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 18/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 19/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 20/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 21/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 22/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 23/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 24/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 25/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 26/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 27/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 28/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 29/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 30/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 31/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 32/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 33/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 34/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 35/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 36/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1105 - val_accuracy: 0.0928\n",
      "Epoch 37/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 38/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 39/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 40/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 41/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 42/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 43/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 44/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 45/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 46/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 47/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 48/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 49/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 50/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 51/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 52/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 53/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 54/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 55/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 56/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 57/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 58/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 59/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 60/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 61/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 62/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 63/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 65/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 66/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 67/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 68/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 69/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 70/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 71/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 72/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 73/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 74/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1106 - val_accuracy: 0.0928\n",
      "Epoch 75/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 76/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 77/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 78/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 79/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 80/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 81/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 82/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 83/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 84/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 85/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 86/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 87/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 88/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 89/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 90/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 91/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 92/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 93/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 94/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 95/300\n",
      "178/178 [==============================] - 24s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 96/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 97/300\n",
      "178/178 [==============================] - 24s 134ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 98/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 99/300\n",
      "178/178 [==============================] - 24s 137ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 100/300\n",
      "178/178 [==============================] - 25s 142ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 101/300\n",
      "178/178 [==============================] - 24s 133ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 102/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 103/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 104/300\n",
      "178/178 [==============================] - 23s 132ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 105/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 106/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 107/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 108/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 109/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 110/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 111/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 112/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 113/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 114/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 115/300\n",
      "178/178 [==============================] - 23s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 116/300\n",
      "178/178 [==============================] - 22s 125ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 117/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1107 - val_accuracy: 0.0928\n",
      "Epoch 118/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 119/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 120/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 121/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 122/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 123/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 124/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 125/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 126/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 127/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 128/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 129/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 130/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 131/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 132/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 133/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 134/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 135/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 136/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 137/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 138/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 139/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 140/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 141/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 142/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 143/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 144/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 145/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 146/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 147/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 148/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 149/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 150/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 151/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 152/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 153/300\n",
      "178/178 [==============================] - 23s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 154/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 155/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 156/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 157/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 158/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 159/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 160/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 161/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1108 - val_accuracy: 0.0928\n",
      "Epoch 162/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 163/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 164/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 165/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 166/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 167/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 168/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 169/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 170/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 171/300\n",
      "178/178 [==============================] - 23s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 172/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 173/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 175/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 176/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 177/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 178/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 179/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 180/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 181/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 182/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 183/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 184/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 185/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 186/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 187/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 188/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 189/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 190/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 191/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 192/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 193/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 194/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 195/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 196/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 197/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 198/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 199/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 200/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 201/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 202/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 203/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1109 - val_accuracy: 0.0928\n",
      "Epoch 204/300\n",
      "178/178 [==============================] - 22s 126ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 205/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 206/300\n",
      "178/178 [==============================] - 23s 130ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 207/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 208/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 209/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 210/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 211/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 212/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 213/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 214/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 215/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 216/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 217/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 218/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 219/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 220/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 221/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 222/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 223/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 224/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 225/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 226/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 227/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 228/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 229/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 230/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 231/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 232/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 233/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 234/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 235/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 236/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 237/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 238/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 239/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 240/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 241/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 242/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 243/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 244/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 245/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1110 - val_accuracy: 0.0928\n",
      "Epoch 246/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 247/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 248/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 249/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 250/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 251/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 252/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 253/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 254/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 255/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 256/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 257/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 258/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 259/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 260/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 261/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 262/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 263/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 264/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 265/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 266/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 267/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 268/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 269/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 270/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 271/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 272/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 273/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 274/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1059 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 275/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 276/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 277/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 278/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 279/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 280/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 281/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 282/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 283/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 285/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 286/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 287/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 288/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 289/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 290/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 291/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 292/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1111 - val_accuracy: 0.0928\n",
      "Epoch 293/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 294/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 295/300\n",
      "178/178 [==============================] - 23s 128ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 296/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 297/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 298/300\n",
      "178/178 [==============================] - 23s 129ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 299/300\n",
      "178/178 [==============================] - 23s 131ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n",
      "Epoch 300/300\n",
      "178/178 [==============================] - 23s 127ms/step - loss: 0.1058 - accuracy: 0.1004 - val_loss: 0.1112 - val_accuracy: 0.0928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.0001 # Define your initial learning rate\n",
    "adam_optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_counter = 1\n",
    "# Train the model using cross-noisy_real\n",
    "for train_index, test_index in kf.split(noisy_real):\n",
    "    #print(train_index, test_index)\n",
    "    \n",
    "    X_train, X_test = noisy_real[train_index], noisy_real[test_index]\n",
    "    y_train, y_test = clean_real[train_index], clean_real[test_index]\n",
    "      \n",
    "    print(f\"Training Fold {fold_counter}\")\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))\n",
    "    \n",
    "    fold_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97e66113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\cuda_tf\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"all_wgn_attnunetresi.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19dadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "aabgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe973fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# si_sdr = ScaleInvariantSignalDistortionRatio()\n",
    "\n",
    "\n",
    "# initial_learning_rate = 0.001  # Define your initial learning rate\n",
    "# adam_optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# # Define the number of folds for cross-validation\n",
    "# num_folds = 10\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# fold_counter = 1\n",
    "# sisdr_values = []  # List to store SNR values for each fold\n",
    "\n",
    "# # Train the model using cross-validation\n",
    "# for train_index, test_index in kf.split(noisy_real):\n",
    "#     X_train, X_test = noisy_real[train_index], noisy_real[test_index]\n",
    "#     y_train, y_test = clean_real[train_index], clean_real[test_index]\n",
    "\n",
    "#     print(f\"Training Fold {fold_counter}\")\n",
    "#     model.fit(X_train, y_train, epochs=150, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "#     # Make predictions\n",
    "#     pred = model.predict(X_test)\n",
    "    \n",
    "#     target = tensor([np.expand_dims(y_test,axis=-1)])\n",
    "#     preds = tensor([pred])\n",
    "\n",
    "#     # Calculate SNR\n",
    "#     sisdr = si_sdr(preds, target)\n",
    "    \n",
    "#     print(f\"sisdr for Fold {fold_counter}: {sisdr} dB\")\n",
    "    \n",
    "#     sisdr_values.append(sisdr)  # Store SNR value for the current fold\n",
    "\n",
    "#     fold_counter += 1\n",
    "\n",
    "# # Calculate the average SNR across all folds\n",
    "# final_sisdr = np.mean(sisdr_values)\n",
    "# print(f\"Final sisdr across all folds: {final_sisdr} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "530b2a39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaaaacvfsv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11560\\248434016.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maaaaacvfsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'aaaaacvfsv' is not defined"
     ]
    }
   ],
   "source": [
    "aaaaacvfsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29e8000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37362646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.340421022458738"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred = model.predict(X_valid)\n",
    "10 * np.log10(np.sum(np.expand_dims(y_valid, axis=-1)**2) / np.sum((np.expand_dims(y_valid, axis=-1) - pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ab3f82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/dataformodel_noaug/noisy_stft_han'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mat_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a01d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88994b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si_sdr = ScaleInvariantSignalDistortionRatio()\n",
    "# target = tensor([np.expand_dims(y_valid,axis=-1)])\n",
    "# preds = tensor([pred])\n",
    "# si_sdr(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e65b8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\cuda_tf\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"unet_attn_wgn0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfe33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b2652e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = model.predict(np.expand_dims(noisy_data_real[np.newaxis, :, :], axis=-1))\n",
    "# p= p.reshape((128, 64))\n",
    "# q = p - noisy_data_real\n",
    "# scipy.io.savemat('New_AS_002_denoise_model0001_aug_cv250_gg.mat', {'denoise_spe':q})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865ab4f",
   "metadata": {},
   "source": [
    "# test unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to load data from a single .mat file\n",
    "# def load_data(file_path):\n",
    "#     loaded_mat = scipy.io.loadmat(file_path)\n",
    "#     return loaded_mat['Segment_clean']  # Replace with the actual variable name\n",
    "\n",
    "# # Define the folder containing the .mat files\n",
    "# mat_folder = 'data/unseenfordenoise/test_clean_stft_aug_wgn-5db'  # Replace with the actual path\n",
    "\n",
    "# # Initialize an empty list to store loaded data\n",
    "# loaded_test_data = []\n",
    "\n",
    "# # List all .mat files in the folder\n",
    "# mat_files = [os.path.join(mat_folder, filename) for filename in os.listdir(mat_folder) if filename.endswith('.mat')]\n",
    "\n",
    "# # Use concurrent processing to load data from multiple files simultaneously\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     loaded_test_data = list(executor.map(load_data, mat_files))\n",
    "\n",
    "# # Concatenate all loaded data into a single variable\n",
    "# test_clean_data = np.stack(loaded_test_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_clean_real = np.real(test_clean_data)\n",
    "# test_clean_img  = np.imag(test_clean_data)\n",
    "# test_clean_real.shape,test_clean_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to load data from a single .mat file\n",
    "# def load_data(file_path):\n",
    "#     loaded_mat = scipy.io.loadmat(file_path)\n",
    "#     return loaded_mat['Segment_noisy']  # Replace with the actual variable name\n",
    "\n",
    "# # Define the folder containing the .mat file\n",
    "# mat_folder = 'data/unseenfordenoise/test_noisy_stft_aug_wgn-5db'  # Replace with the actual path\n",
    "\n",
    "# # Initialize an empty list to store loaded data\n",
    "# loaded_test_data = []\n",
    "\n",
    "# # List all .mat files in the folder\n",
    "# mat_files = [os.path.join(mat_folder, filename) for filename in os.listdir(mat_folder) if filename.endswith('.mat')]\n",
    "\n",
    "# # Use concurrent processing to load data from multiple files simultaneously\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     loaded_test_data = list(executor.map(load_data, mat_files))\n",
    "\n",
    "# # Concatenate all loaded data into a single variable\n",
    "# test_noisy_data = np.stack(loaded_test_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_noisy_real = np.real(test_noisy_data)\n",
    "# test_noisy_img  = np.imag(test_noisy_data)\n",
    "# test_noisy_real.shape,test_noisy_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762dbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd76d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(test_noisy_real)\n",
    "# 10 * np.log10(np.sum(np.expand_dims(test_clean_real, axis=-1)**2) / np.sum((np.expand_dims(test_clean_real, axis=-1) - pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si_sdr = ScaleInvariantSignalDistortionRatio()\n",
    "# target = tensor([np.expand_dims(test_clean_real,axis=-1)])\n",
    "# preds = tensor([pred])\n",
    "# si_sdr(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fdaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96262b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f40d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17c5051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\cuda_tf\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('denoisy_attnunet_0dbwg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf4e08",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db1b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model from the file\n",
    "modell = load_model(\"model\\mix_model_attn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eab2d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the denoised spectrograms\n",
    "denoised_spectrograms = []\n",
    "\n",
    "# Specify the directory containing the noisy data files\n",
    "noisy_data_directory = 'test_noisy_data/'\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(noisy_data_directory):\n",
    "    if file_name.endswith('.mat'):\n",
    "        # Load the noisy data from the MAT file\n",
    "        file_path = os.path.join(noisy_data_directory, file_name)\n",
    "        test_noisy_data = scipy.io.loadmat(file_path)['Segment_noisy']\n",
    "\n",
    "        noisy_data_real = np.real(test_noisy_data)\n",
    "        noisy_data_imag = np.imag(test_noisy_data)\n",
    "        \n",
    "        \n",
    "        # Expand dimensions\n",
    "        noisy_data_real = np.expand_dims(noisy_data_real[np.newaxis, :, :], axis=-1)\n",
    "\n",
    "        # Apply the model to denoise the data\n",
    "        denoised_data_real = modell.predict(noisy_data_real)\n",
    "\n",
    "        denoised_data_real = denoised_data_real.reshape((128, 64))\n",
    "        \n",
    "        # Reshape to (128, 64)\n",
    "        #denoised_data = np.vectorize(complex)(denoised_data_real, noisy_data_imag)\n",
    "        \n",
    "\n",
    "        # Append the denoised data to the list\n",
    "        denoised_spectrograms.append(denoised_data_real)\n",
    "\n",
    "# Stack the denoised spectrograms along a new axis (4D array)\n",
    "merged_denoised_data = np.concatenate(denoised_spectrograms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "466a094b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 320)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_denoised_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed2e69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('New_AS_002_denoise_model0001_aug_cv250.mat', {'denoise_spe': merged_denoised_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "968a3642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.3229254e-02,  6.2912568e-02,  1.4227118e-01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-3.8272759e-01,  3.0651870e-01, -8.8779166e-02, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 7.1703506e-01, -1.1901593e+00,  3.0767056e-01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       ...,\n",
       "       [ 2.4114050e-05,  1.0826528e-03, -9.6957019e-04, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-3.7938808e-05, -8.5382385e-04, -4.6788628e-04, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.4672104e-04, -1.1342473e-03,  2.0025505e-03, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_denoised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946aa88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
